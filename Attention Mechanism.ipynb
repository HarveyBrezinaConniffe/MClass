{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harvey/tf-env/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\\npolicy = mixed_precision.Policy('mixed_float16')\\nmixed_precision.set_policy(policy)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow_addons as tfa\n",
    "import csv\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the tfrecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['records/train10-2071.tfrec', 'records/train12-2071.tfrec', 'records/train11-2071.tfrec', 'records/train06-2071.tfrec', 'records/train03-2071.tfrec', 'records/train02-2071.tfrec', 'records/train05-2071.tfrec', 'records/train13-2071.tfrec', 'records/train01-2071.tfrec', 'records/train15-2061.tfrec', 'records/train14-2071.tfrec', 'records/train07-2071.tfrec', 'records/train00-2071.tfrec', 'records/train08-2071.tfrec', 'records/train04-2071.tfrec', 'records/train09-2071.tfrec']\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "from os import walk\n",
    "for (dirpath, dirnames, filenames) in walk(\"records/\"):\n",
    "    for f in filenames:\n",
    "        if \"train\" in f:\n",
    "            records.append(\"records/{}\".format(f))\n",
    "\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filenames = records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    'target': tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the amount of images for each patient in patient_image_count.\n",
    "<br>\n",
    "Store a mappting of image name -> patient id in image_to_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_image_count = {}\n",
    "image_to_patient = {}\n",
    "\n",
    "with open(\"train.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    headings = next(reader)\n",
    "    for im in reader:\n",
    "        name = im[0]\n",
    "        patient_id = im[1]\n",
    "        if patient_id not in patient_image_count:\n",
    "            patient_image_count[patient_id] = 0\n",
    "        patient_image_count[patient_id] += 1\n",
    "        image_to_patient[name] = patient_id\n",
    "        #print(i, cimages[i][\"Target\"], ctarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence is: 240\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 16\n",
    "channels = 3\n",
    "\n",
    "#longest = max(patient_image_count.values())\n",
    "longest = 240\n",
    "print(\"Longest sequence is: {}\".format(longest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize each patient's structure as follows:<br>\n",
    "In the 'Targets' array we will store a (longest,) numpy array for each patient containing the targets for each image.<br>\n",
    "In the 'Masks' array we will store a (longest,) numpy array for each patient containing it's mask.<br>\n",
    "In the 'Images' array we will store a (longest X IMG_SIZE X IMG_SIZE X 3) numpy array for each patient containing the images.<br>\n",
    "In the 'Written' array we will store an index of how many examples have been written for each patient, This will be useful in the next step.<br>\n",
    "In the 'Patient_Order' array we will store a mapping of patient_name -> position in other array, This will be useful in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "masks = []\n",
    "images = []\n",
    "\n",
    "written = []\n",
    "patient_order = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for patient in patient_image_count.keys():\n",
    "    pad_val = -1\n",
    "    target_arr = np.full((longest,), pad_val)\n",
    "    mask_arr = np.ones((longest,))\n",
    "    image_arr = np.zeros((longest, IMG_SIZE, IMG_SIZE, channels))\n",
    "    \n",
    "    targets.append(target_arr)\n",
    "    masks.append(mask_arr)\n",
    "    images.append(image_arr)\n",
    "    \n",
    "    written.append(0)\n",
    "    patient_order[patient] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the dataset and do the following for each example:\n",
    "<br>\n",
    "Parse it's image and get the images name.<br>\n",
    "Find out which patient the image is for.<br>\n",
    "Find out where in the order this patient is.<br>\n",
    "Find how many images have been written for this patient.<br>\n",
    "Increment this patients written value.<br>\n",
    "Write the image to the correct position in this patients image array.<br>\n",
    "Write the target to the correct position in this patients target array.<br>\n",
    "Set the mask value to 0 in the correct position in this patients mask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in dataset:\n",
    "    # Parse image.\n",
    "    example = tf.io.parse_single_example(image, feature_description)\n",
    "    img = tf.io.decode_image(example['image'], expand_animations = False, channels=channels)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/127.5) - 1\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Get image name.\n",
    "    name = example['image_name'].numpy().decode(\"utf_8\")\n",
    "\n",
    "    # Get image target.\n",
    "    target = example['target'].numpy()\n",
    "    \n",
    "    # Work out which patient this belongs to.\n",
    "    patient = image_to_patient[name]\n",
    "    \n",
    "    # Find out patient's index.\n",
    "    patient_index = patient_order[patient]\n",
    "    \n",
    "    # Find how many images have been written to this patient.\n",
    "    written_index = written[patient_index]\n",
    "    \n",
    "    # Write image.\n",
    "    images[patient_index][written_index, :, :, :] = img\n",
    "    \n",
    "    # Write target.\n",
    "    targets[patient_index][written_index] = target\n",
    "    \n",
    "    # Set mask to 0.\n",
    "    masks[patient_index][written_index] = 0\n",
    "    \n",
    "    # Increment written value.\n",
    "    written[patient_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0][0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(targets)\n",
    "#for i in iter(alldata):\n",
    "#    total += 1\n",
    "#print(\"{} images in total.\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0.66\n",
    "val = 0.33\n",
    "\n",
    "train_num = int(total*train)\n",
    "val_num = int(total*val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(masks)):\n",
    "    masks[i] = np.reshape(masks[i], (1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = np.array(targets[0:train_num])\n",
    "val_targets = np.array(targets[train_num:])\n",
    "\n",
    "train_masks = np.array(masks[0:train_num])\n",
    "val_masks = np.array(masks[train_num:])\n",
    "\n",
    "train_images = np.array(images[0:train_num])\n",
    "val_images = np.array(images[train_num:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 240)\n",
      "(700, 240)\n",
      "(1356, 240, 16, 16, 3)\n",
      "(700, 240, 16, 16, 3)\n",
      "(1356, 1, 1, 240)\n",
      "(700, 1, 1, 240)\n"
     ]
    }
   ],
   "source": [
    "print(train_targets.shape)\n",
    "print(val_targets.shape)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(val_images.shape)\n",
    "\n",
    "print(train_masks.shape)\n",
    "print(val_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 1,  0,  0, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., -1, -1, -1],\n",
       "       [ 0,  0,  1, ..., -1, -1, -1],\n",
       "       [ 0,  0,  0, ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions for model, Most of these are heavily inspired by( Some just copy-pasted ) from the official tensorflow tutorial on Transformer networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    # Matrix multiply the querys by the keys\n",
    "    qk = tf.matmul(q, k, transpose_b=True, name=\"queryXkey\")\n",
    "    \n",
    "    # Get the dimension of the keys and scale the attention by it\n",
    "    key_dim = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention = tf.cast(qk, tf.float32)/tf.math.sqrt(key_dim)\n",
    "    \n",
    "    # Use the mask to set the masked images( The padding ) to a very small number. Softmax will zero these out.\n",
    "    canceller = mask*-(10**9)\n",
    "    \n",
    "    scaled_attention += canceller\n",
    "    \n",
    "    # Softmax the attention weights\n",
    "    attention_weights = tf.nn.softmax(scaled_attention, axis=-1, name=\"softmax_attention\")\n",
    "    \n",
    "    # Multiply the values by the weights\n",
    "    out = tf.matmul(attention_weights, tf.cast(v, tf.float32), name=\"attention_out\")\n",
    "    \n",
    "    return out, attention_weights\n",
    "    '''\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "          \n",
    "  def call(self, x, training, mask):\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_embedding_net(filters, out_dim, name):\n",
    "    inp = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, channels))\n",
    "    conv = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\")(inp)\n",
    "    conv = Conv2D(filters//2, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\")(conv)\n",
    "    maxpool = MaxPool2D(pool_size=(5, 5))(conv)\n",
    "    flatten = Flatten()(maxpool)\n",
    "    out = Dense(out_dim)(flatten)\n",
    "    submodel = tf.keras.Model(name=name, inputs=[inp], outputs=[out])\n",
    "    return submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_net(vec_shape, dimension, name):\n",
    "    inp = tf.keras.Input(shape=(vec_shape,))\n",
    "    internal = Dense(dimension, activation=\"relu\")(inp)\n",
    "    internal = BatchNormalization()(internal)\n",
    "    output = Dense(1, activation=\"sigmoid\")(internal)\n",
    "    submodel = tf.keras.Model(name=name, inputs=[inp], outputs=[output])\n",
    "    return submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_filters = 128\n",
    "\n",
    "transformer_layers = 6\n",
    "transformer_dimension = 512\n",
    "num_heads = 8\n",
    "\n",
    "transformer_ff_dimension = 2048\n",
    "\n",
    "out_hidden_dimension = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS SHAPE:\n",
      "(None, 240, 512)\n",
      "(None, 240, 512)\n",
      "(None, 512)\n",
      "Tensor(\"output_net/dense_38/Sigmoid:0\", shape=(None, 1), dtype=float32)\n",
      "(None, 240)\n"
     ]
    }
   ],
   "source": [
    "num_images = longest\n",
    "\n",
    "# Create input for images and masks.\n",
    "images_in = tf.keras.Input(name=\"Images_In\", shape=(num_images, IMG_SIZE, IMG_SIZE, channels))\n",
    "mask_in  = tf.keras.Input(name=\"Mask_In\", shape=(1, 1, num_images))\n",
    "\n",
    "# Create ConvNet to compute query, key and value vectors\n",
    "embedding_net = create_image_embedding_net(embedding_filters, transformer_dimension, \"embedding_net\")\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    img = images_in[:, i, :, :, :]\n",
    "    embeddings.append(embedding_net(img))\n",
    "\n",
    "embeddings = tf.stack(embeddings, axis=1)\n",
    "print(\"EMBEDDINGS SHAPE:\")\n",
    "print(embeddings.shape)\n",
    "\n",
    "transformer = Encoder(num_layers=transformer_layers, d_model=transformer_dimension, num_heads=num_heads, dff=transformer_ff_dimension)\n",
    "\n",
    "new_image_vectors = transformer(embeddings, True, mask_in)\n",
    "print(new_image_vectors.shape)\n",
    "print(new_image_vectors[:, 0, :].shape)\n",
    "\n",
    "output_net = create_output_net(transformer_dimension, out_hidden_dimension, \"output_net\")\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    img_vec = new_image_vectors[:, i, :]\n",
    "    cout = output_net(img_vec)\n",
    "    outputs.append(cout)\n",
    "\n",
    "print(outputs[0])\n",
    "output = tf.stack(outputs, axis=-1)[:, 0, :]\n",
    "print(output.shape)\n",
    "\n",
    "model = tf.keras.Model(inputs=[images_in, mask_in], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embed_net = create_image_embedding_net(embedding_filters, transformer_dimension, \"embedding_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in range(10):\n",
    "    embeddings.append(test_embed_net(np.array([images[0][i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_stack = tf.stack(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision - \n",
    "How many of the melanoma that we said are bad were actually bad?\n",
    "Recall -\n",
    "How many of the bad melanoma did we catch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def create_loss_func():\n",
    "    \n",
    "    bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    def loss_function(real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, -1))\n",
    "        ctarget = tf.math.equal(real, 1)\n",
    "        loss_ = bce(ctarget, pred)\n",
    "\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        print(\"LMASK\")\n",
    "        print(mask)\n",
    "        loss_ *= mask\n",
    "        print(\"LOSS-MASKED\")\n",
    "        print(loss_)\n",
    "\n",
    "        return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "    \n",
    "    return loss_function\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_log_loss():\n",
    "    def loss_function(real, pred):\n",
    "        epsilon = 9*(10**-5)\n",
    "        \n",
    "        mask = tf.math.logical_not(tf.math.equal(real, -1))\n",
    "        ctarget = tf.math.equal(real, 1)\n",
    "\n",
    "        #print(\"PREDICTIONS\")\n",
    "        #print(pred)\n",
    "        #print(\"ADDED EPSILON\")\n",
    "        #print(pred+epsilon)\n",
    "        \n",
    "        positive_loss = tf.math.log(pred+epsilon)\n",
    "        negative_loss = tf.math.log((1-pred)+epsilon)\n",
    "        \n",
    "        #print(\"POSITIVE LOSS\")\n",
    "        #print(positive_loss)\n",
    "        #print(\"NEGATIVE LOSS\")\n",
    "        #print(negative_loss)\n",
    "        \n",
    "        ctarget = tf.cast(ctarget, dtype=positive_loss.dtype)\n",
    "        \n",
    "        positive_loss = positive_loss*ctarget\n",
    "        negative_loss = negative_loss*(1-ctarget)\n",
    "        \n",
    "        loss_ = positive_loss+negative_loss\n",
    "        loss_ *= -1\n",
    "        \n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ = loss_*mask\n",
    "        \n",
    "        loss_ = tf.reduce_sum(loss_)\n",
    "        \n",
    "        return loss_\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "          loss=masked_log_loss(),\n",
    "          metrics=[\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "170/170 [==============================] - 40s 236ms/step - loss: 12.3781 - auc: 0.6232 - val_loss: 8.5477 - val_auc: 0.6511\n",
      "Epoch 2/1000\n",
      "170/170 [==============================] - 41s 239ms/step - loss: 12.3419 - auc: 0.6364 - val_loss: 8.3989 - val_auc: 0.6437\n",
      "Epoch 3/1000\n",
      "170/170 [==============================] - 41s 242ms/step - loss: 12.4457 - auc: 0.6291 - val_loss: 8.2332 - val_auc: 0.6527\n",
      "Epoch 4/1000\n",
      " 47/170 [=======>......................] - ETA: 25s - loss: 12.9739 - auc: 0.6531"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-92e1bc155767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#hist = model.fit([train_images, train_masks], train_targets, validation_data=([val_images, val_masks], val_targets),epochs=100, callbacks=[stopper], batch_size=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf-env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "#hist = model.fit([train_images, train_masks], train_targets, validation_data=([val_images, val_masks], val_targets),epochs=100, callbacks=[stopper], batch_size=1)\n",
    "\n",
    "hist = model.fit([train_images, train_masks], train_targets, validation_data=([val_images, val_masks], val_targets), epochs=1000, batch_size=8, callbacks=[stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['records/test01-687.tfrec', 'records/test02-687.tfrec', 'records/test08-687.tfrec', 'records/test09-687.tfrec', 'records/test10-687.tfrec', 'records/test15-677.tfrec', 'records/test06-687.tfrec', 'records/test04-687.tfrec', 'records/test07-687.tfrec', 'records/test14-687.tfrec', 'records/test05-687.tfrec', 'records/test11-687.tfrec', 'records/test13-687.tfrec', 'records/test00-687.tfrec', 'records/test03-687.tfrec', 'records/test12-687.tfrec']\n"
     ]
    }
   ],
   "source": [
    "testrecords = []\n",
    "from os import walk\n",
    "for (dirpath, dirnames, filenames) in walk(\"records/\"):\n",
    "    for f in filenames:\n",
    "        if \"test\" in f:\n",
    "            testrecords.append(\"records/{}\".format(f))\n",
    "\n",
    "print(testrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description_test = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(filenames = testrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patient_image_count = {}\n",
    "test_image_to_patient = {}\n",
    "\n",
    "with open(\"test.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    headings = next(reader)\n",
    "    for im in reader:\n",
    "        name = im[0]\n",
    "        patient_id = im[1]\n",
    "        if patient_id not in test_patient_image_count:\n",
    "            test_patient_image_count[patient_id] = 0\n",
    "        test_patient_image_count[patient_id] += 1\n",
    "        test_image_to_patient[name] = patient_id\n",
    "        #print(i, cimages[i][\"Target\"], ctarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_masks = []\n",
    "test_images = []\n",
    "\n",
    "test_written = []\n",
    "test_patient_order = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "for patient in test_patient_image_count.keys():\n",
    "    mask_arr = np.ones((longest,))\n",
    "    image_arr = np.zeros((longest, IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    test_masks.append(mask_arr)\n",
    "    test_images.append(image_arr)\n",
    "    \n",
    "    test_written.append(0)\n",
    "    test_patient_order[patient] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence is: 240\n"
     ]
    }
   ],
   "source": [
    "test_longest = max(test_patient_image_count.values())\n",
    "print(\"Longest sequence is: {}\".format(test_longest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([240, 46, 28, 38, 29, 55, 12, 16, 7, 12, 66, 90, 9, 29, 4, 93, 28, 29, 20, 28, 12, 29, 12, 24, 6, 108, 41, 80, 11, 11, 13, 50, 16, 21, 16, 17, 43, 49, 34, 63, 52, 38, 29, 22, 19, 9, 62, 27, 29, 21, 11, 31, 3, 16, 30, 5, 20, 15, 4, 10, 21, 10, 22, 68, 35, 8, 12, 58, 9, 58, 5, 47, 22, 13, 15, 3, 5, 25, 63, 32, 20, 31, 6, 32, 22, 48, 28, 20, 5, 5, 67, 21, 22, 26, 9, 12, 32, 8, 62, 43, 5, 29, 21, 21, 20, 47, 23, 9, 14, 20, 38, 33, 17, 15, 39, 33, 36, 10, 63, 39, 17, 37, 8, 4, 15, 6, 9, 37, 21, 20, 33, 10, 12, 52, 41, 16, 7, 10, 29, 40, 7, 63, 13, 10, 38, 30, 49, 16, 26, 14, 17, 28, 22, 44, 25, 28, 19, 26, 27, 21, 9, 29, 33, 15, 50, 8, 6, 5, 47, 15, 29, 13, 5, 7, 23, 21, 18, 6, 22, 30, 8, 14, 19, 20, 10, 11, 3, 13, 4, 22, 14, 22, 37, 46, 11, 21, 29, 10, 6, 3, 5, 26, 8, 12, 9, 46, 48, 22, 13, 7, 6, 30, 30, 14, 53, 13, 4, 24, 24, 29, 23, 4, 46, 18, 12, 10, 10, 15, 8, 8, 7, 40, 24, 26, 36, 51, 5, 9, 10, 8, 23, 11, 7, 19, 14, 16, 9, 14, 4, 4, 41, 10, 21, 17, 3, 9, 54, 12, 16, 52, 8, 6, 14, 52, 14, 23, 16, 18, 13, 11, 23, 8, 3, 23, 22, 37, 4, 11, 42, 15, 21, 5, 13, 4, 21, 24, 31, 21, 13, 7, 21, 22, 6, 39, 17, 9, 25, 26, 17, 32, 20, 19, 39, 26, 52, 24, 11, 6, 39, 8, 35, 15, 9, 27, 13, 10, 9, 19, 10, 9, 15, 23, 10, 11, 14, 8, 14, 11, 34, 38, 18, 5, 3, 9, 22, 21, 10, 32, 15, 8, 11, 29, 12, 12, 11, 22, 15, 38, 13, 4, 14, 27, 11, 19, 28, 10, 4, 20, 6, 7, 29, 22, 10, 35, 23, 24, 3, 10, 28, 35, 3, 8, 12, 14, 8, 6, 4, 5, 4, 13, 10, 7, 19, 4, 3, 9, 10, 8, 12, 4, 13, 18, 12, 6, 10, 18, 5, 8, 7, 10, 25, 42, 3, 7, 5, 10, 31, 4, 14, 10, 10, 6, 14, 3, 8, 15, 7, 32, 13, 3, 15, 3, 10, 47, 4, 6, 5, 11, 6, 6, 8, 3, 19, 4, 7, 4, 6, 4, 9, 7, 10, 12, 3, 5, 10, 6, 3, 9, 18, 14, 4, 30, 7, 5, 6, 13, 6, 4, 7, 23, 3, 28, 5, 19, 3, 5, 21, 3, 5, 9, 4, 6, 3, 10, 7, 9, 9, 10, 5, 4, 8, 14, 23, 18, 22, 10, 16, 5, 14, 10, 8, 4, 12, 6, 29, 4, 4, 4, 5, 8, 10, 10, 6, 4, 20, 14, 15, 4, 14, 16, 4, 12, 4, 3, 8, 4, 13, 43, 12, 6, 14, 11, 5, 8, 5, 11, 18, 6, 15, 7, 6, 5, 3, 25, 3, 10, 7, 7, 7, 5, 7, 7, 3, 3, 4, 6, 7, 11, 12, 6, 6, 3, 6, 4, 8, 4, 12, 3, 5, 13, 3, 12, 9, 9, 4, 3, 15, 5, 8, 5, 10, 7, 13, 9, 6, 25, 7, 6, 12, 4, 7, 10, 6, 8, 4, 7, 11, 6, 6, 3, 4, 3, 3, 3, 3, 5, 5, 10, 6, 7, 4, 12, 5, 4, 5, 4, 17, 7, 7, 7, 3, 13, 7, 3, 9, 3, 4, 3, 7, 15, 3, 4, 7, 3, 8, 6, 9, 3, 8, 6, 5, 6, 5, 5, 4, 4, 3, 5, 4, 9, 3, 6, 6, 4, 5, 4, 4, 4, 9, 7, 17, 9, 6, 3, 5, 5, 3, 5, 4, 4, 10, 4, 5, 5, 5, 10, 5, 4, 5, 4, 3, 3, 5, 4, 7, 4, 3, 3, 4, 3, 3, 5, 4, 3, 3, 4, 3, 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(test_patient_image_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([val_images, val_masks], val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "for p in test_patient_image_count.values():\n",
    "    if p >= 115:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_orders = {}\n",
    "bad_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in test_dataset:\n",
    "    # Parse image.\n",
    "    example = tf.io.parse_single_example(image, feature_description_test)\n",
    "    img = tf.io.decode_image(example['image'], expand_animations = False, channels=channels)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/127.5) - 1\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Get image name.\n",
    "    name = example['image_name'].numpy().decode(\"utf_8\")\n",
    "    \n",
    "    # Work out which patient this belongs to.\n",
    "    patient = test_image_to_patient[name]\n",
    "    \n",
    "    # Find out patient's index.\n",
    "    patient_index = test_patient_order[patient]\n",
    "    \n",
    "    if patient_index not in test_image_orders:\n",
    "        test_image_orders[patient_index] = []\n",
    "    \n",
    "    test_image_orders[patient_index].append(name)\n",
    "    \n",
    "    # Find how many images have been written to this patient.\n",
    "    written_index = test_written[patient_index]\n",
    "    #if written_index >= 115:\n",
    "    #    bad_images.append(name)\n",
    "    #    continue\n",
    "    \n",
    "    # Write image.\n",
    "    test_images[patient_index][written_index, :, :, :] = img\n",
    "        \n",
    "    # Set mask to 0.\n",
    "    test_masks[patient_index][written_index] = 0\n",
    "    \n",
    "    # Increment written value.\n",
    "    test_written[patient_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6b6f139e3530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_masks)):\n",
    "    test_masks[i] = np.reshape(test_masks[i], (1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_masks = np.array(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([test_images, test_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "patient_index = 0\n",
    "\n",
    "with open(\"submission.csv\", \"w\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    writer.writerow([\"image_name\", \"target\"])\n",
    "    for patient in predictions:\n",
    "        num_ims = min(len(test_image_orders[patient_index]), 240)\n",
    "        for i in range(num_ims):\n",
    "            image = patient[i]\n",
    "            name = test_image_orders[patient_index][i]\n",
    "            prounded = f\"{image:.9f}\"\n",
    "            writer.writerow([name, prounded])\n",
    "        patient_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"submission.csv\", \"a\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    for b in bad_images:\n",
    "        prounded = f\"{random.random():.9f}\"\n",
    "        writer.writerow([b, prounded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
